
================================
RIC (near RT RIC) in Kubernetes
================================

0. pre-requisite
----------------
RIC source download 
git clone "https://gerrit.o-ran-sc.org/r/ric-plt/ric-dep"

online Installation Guide
https://docs.o-ran-sc.org/projects/o-ran-sc-ric-plt-ric-dep/en/latest/installation-guides.html



1. Install k8s
---------------
3 options
(option.1)
use script, https://jira.o-ran-sc.org/projects/RIC/issues/RIC-1053?filter=allissues
    install_k8s_docker_helm_v1.28-Anusha.sh
    --> install v1.28  kubeadm, kubectl, kubelet with docker but actullay containerd 
                helm v3.14.2
or
(option.2)
my modified script, 
   install_k8s_and_helm(osc)-modified-KL.sh (this version uses clusterConfiguration yaml for kubeadm init)
    --> install v1.29 kubeadm kubelet kubectl with containerd
                helm v3.5.2

or
(option.3)
my modified script, 
   install_k8s_helm_prereq-commands.sh
    - same with install_k8s_and_helm(osc)-modified-KL.sh, but kubeadm init with one-liner configuration
    - added helm v3.14.2
	- execute ./install_common_templates_to_helm.sh at the end



2.  kong install
----------------
2 options
(option.1)
use script, https://jira.o-ran-sc.org/projects/RIC/issues/RIC-1053?filter=allissues
    install_kong-Anusha.sh

    It also includes
    - change v1beta1 to v1
    - remove ingress features in yaml configuration 
		cd ${RICPATH}/helm/appmgr/templates; rm ingress-appmgr.yaml
		cd ${RICPATH}/helm/e2mgr/templates; rm ingress-e2mgr.yaml
		cd ${RICPATH}/helm/a1mediator/templates; rm ingress-a1mediator.yaml


(option.2)
  This is what I did manually to install kong in order to avoid errors

	 --------- 1. Need to diable Kong setting first  ------------
	 install without kong enabled
	 --> In values.yaml need to change kong enabled parameter as false under ric-dep/helm/infrastructure folder.
		 Kong pod will be in crashloopbackoff if we enabled as true


	 -------  2.  Replace serviceName, servicePort in v1beta1 to service.name, service.port.number in v1
	 they will be found at ./ric-dep/helm/a1mediator/templates/ingress-a1mediator.yaml
	 ./install -f  ../RECIPE_EXAMPLE/example_recipe_oran_i_release.yaml
	 --> this command leads to the next actual helm install command

	 helm install -f ../RECIPE_EXAMPLE/example_recipe_oran_i_release.yaml --namespace ricplt r4-infrastructure /root/ric-dep/bin/../he


	 --- 3. install Kong ---
	helm repo add kong https://charts.konghq.com
	helm repo update
	# helm install kong kong/ingress -n ricplt <-- instead of this, use following command
	helm install -f ~/ric-dep/helm/infrastructure/subcharts/kong/values.yaml kong kong/ingress -n ricplt






3.  Modify the deployment recipe: modify extsvcplt
---------------------------------------------------
 Not sure if this needed or not


 in ric-dep/RECIPE_EXAMPLE/example_recipe_latest_stable.yaml, or example_recipe_oran_i_release 

 change following section to node's real ip
   extsvcplt:
	  riccp:"10.0.0.1" 	--> 192.168.10.124 or 10.0.2.15
	  auxip:"10.0.0.1"	--> 192.168.10.124 or 10.0.2.15
	







4. install common teamplte to helm 
-----------------------------------

root@ran3:~/ric-dep/bin# ./install_common_templates_to_helm.sh
	- install chartmuseum into helm with "helm servecm"
	- install ric-common template into helm by chartmuseum





5. Installing the RIC
----------------------
 in ric-dep/bin
	./install -f  ../RECIPE_EXAMPLE/example_recipe_oran_i_release.yaml

	root@ran3:~/ric-dep/bin# ./install -f  ../RECIPE_EXAMPLE/example_recipe_oran_i_release.yaml


NAMESPACE↑    NAME                                                        PF READY STATUS            RESTARTS IP           NODE
kong          kong-controller-55b777f995-2wqxc                            ●  1/1   Running                  0 10.244.0.5   ran3
kong          kong-gateway-868d48556c-sz9js                               ●  1/1   Running                  0 10.244.0.4   ran3
kube-flannel  kube-flannel-ds-lvfsg                                       ●  1/1   Running                  0 10.0.2.15    ran3
kube-system   coredns-5dd5756b68-nqt75                                    ●  1/1   Running                  0 10.244.0.2   ran3
kube-system   coredns-5dd5756b68-q85fw                                    ●  1/1   Running                  0 10.244.0.3   ran3
kube-system   etcd-ran3                                                   ●  1/1   Running                  0 10.0.2.15    ran3
kube-system   kube-apiserver-ran3                                         ●  1/1   Running                  0 10.0.2.15    ran3
kube-system   kube-controller-manager-ran3                                ●  1/1   Running                  0 10.0.2.15    ran3
kube-system   kube-proxy-7bhfk                                            ●  1/1   Running                  0 10.0.2.15    ran3
kube-system   kube-scheduler-ran3                                         ●  1/1   Running                  0 10.0.2.15    ran3
ricinfra      deployment-tiller-ricxapp-676dfd8664-9czh8                  ●  1/1   Running                  0 10.244.0.10  ran3
ricinfra      tiller-secret-generator-qn2kd                               ●  0/1   Completed                0 10.244.0.7   ran3
ricplt        deployment-ricplt-a1mediator-64fd4bf64-77wv2                ●  1/1   Running                  0 10.244.0.14  ran3
ricplt        deployment-ricplt-alarmmanager-7d47d8f4d4-xzmhp             ●  1/1   Running                  0 10.244.0.19  ran3
ricplt        deployment-ricplt-appmgr-5bdd7cbb54-pmd9c                   ●  1/1   Running                  0 10.244.0.11  ran3
ricplt        deployment-ricplt-e2mgr-b988db566-6gn97                     ●  1/1   Running                  0 10.244.0.13  ran3
ricplt        deployment-ricplt-e2term-alpha-75d8ccb646-dw6pf             ●  1/1   Running                  0 10.244.0.15  ran3
ricplt        deployment-ricplt-o1mediator-76c4646878-szk4v               ●  1/1   Running                  0 10.244.0.18  ran3
ricplt        deployment-ricplt-rtmgr-6556c5bc7b-c2pdz                    ●  1/1   Running                  2 10.244.0.12  ran3
ricplt        deployment-ricplt-submgr-599754c984-jc7nr                   ●  1/1   Running                  0 10.244.0.16  ran3
ricplt        deployment-ricplt-vespamgr-786666549b-vtbwc                 ●  1/1   Running                  0 10.244.0.17  ran3
ricplt        r4-infrastructure-prometheus-alertmanager-64f9876d6d-9nsvp  ●  2/2   Running                  0 10.244.0.8   ran3
ricplt        r4-infrastructure-prometheus-server-bcc8cc897-6cbcw         ●  1/1   Running                  0 10.244.0.6   ran3
ricplt        statefulset-ricplt-dbaas-server-0                           ●  1/1   Running                  0 10.244.0.9   ran3



========================
 RIC application, xApps
========================

1. chartmuseum in docker 
------------------------

docker run for running chartmuseum 

	docker run --rm -u 0 -it -d -p 8090:8080 -e DEBUG=1 -e STORAGE=local -e STORAGE_LOCAL_ROOTDIR=/charts -v $(pwd)/charts:/charts chartmuseum/chartmuseum:latest

root@ran3:~/hw-python/init# docker ps
CONTAINER ID   IMAGE                            COMMAND          CREATED          STATUS          PORTS                                       NAMES
eefa2a2beb3a   chartmuseum/chartmuseum:latest   "/chartmuseum"   38 minutes ago   Up 38 minutes   0.0.0.0:8090->8080/tcp, :::8090->8080/tcp   stoic_dhawan



- even though chartmuseum is running on helm with servccm, docker can run chartmuseum in the container
  root@ran3:~/ric-dep/bin# ps aux | grep museum
  root       52655  0.0  0.3 844700 38168 pts/0    Sl   11:19   0:00 chartmuseum --port=8879 --context-path=/charts --storage local --storage-local-rootdir /root/.cache/helm/repository/local/


- Set up the environment variables for CLI connection using the same port as used above.
	--> this is because docker run opens 8090

	#Set CHART_REPO_URL env variable
	export CHART_REPO_URL=http://0.0.0.0:8090




2. Install dms_cli tool
-------------------------
(0) How it works: 
	https://hackmd.io/@Min-xiang/HJZF3-xgt


(1) Instalation guide
	#Git clone appmgr
	git clone "https://gerrit.o-ran-sc.org/r/ric-plt/appmgr"

	#Change dir to xapp_onboarder
	cd appmgr/xapp_orchestrater/dev/xapp_onboarder

	#If pip3 is not installed, install using the following command
	yum install python3-pip

	#In case dms_cli binary is already installed, it can be uninstalled using following command
	pip3 uninstall xapp_onboarder

	#Install xapp_onboarder using following command
	pip3 install ./


	(optional)
	 chmod 755 /usr/local/bin/dms_cli
	 chmod -R 755 /usr/local/lib/python3.8


(2) execution 
	root@ran3:~/ric-dep/bin/appmgr/xapp_orchestrater/dev/xapp_onboarder# dms_cli health
	Failed to connect to helm chart repo http://0.0.0.0:8080 after 3 retries and 1.8071374893188477 seconds. (Caused by: ConnectionError)
	False

	--> without CHART_REPO_URL set, it tried to connect to the port, 8080 as a default, maybe

	- set env variable
	root@ran3:~/ric-dep/bin/appmgr/xapp_orchestrater/dev/xapp_onboarder# export CHART_REPO_URL=http://0.0.0.0:8090
	root@ran3:~/ric-dep/bin/appmgr/xapp_orchestrater/dev/xapp_onboarder# dms_cli health
	True

	--> then it's ok






3. Software, xApp, Installation and Deployment - hw-python
-----------------------------------------------------------
https://github.com/o-ran-sc/ric-app-hw-python
https://wiki.o-ran-sc.org/download/attachments/51904936/demo_f_release.txt?version=2&modificationDate=1655964027497&api=v2


(1) configure the export CHART_REPO_URL to point chartmuseme
	export CHART_REPO_URL=http://0.0.0.0:8090


(2) Onboarding 
	dms_cli onboard with config file and schema file
	
	- config files
	  cd init folder, those two files are found

		root@ran3:~/hw-python/init# ls
		config-file.json  init_script.py  schema.json  test_route.rt
	
	- onboard command,

	  root@ran3:~/hw-python/init# dms_cli onboard --config_file_path=config-file.json --shcema_file_path=schema.json
	  {
			"status": "Created"
	  }



(3) check if hw-python is onboarded,

	root@ran3:~/hw-python/init# dms_cli get_charts_list
	{
		"hw-python": [
			{
				"apiVersion": "v1",
				"appVersion": "1.0",
				"created": "2024-04-23T15:43:43.399273639Z",
				"description": "Standard xApp Helm Chart",
				"digest": "deb21c533192227fc33c43ee5953428c912f73665d03e257473244d19ed9ca08",
				"name": "hw-python",
				"urls": [
					"charts/hw-python-1.0.0.tgz"
				],
				"version": "1.0.0"
			}
		]
	}



	** To check where hw-python is downloaded,

	- docker is ruuning with the volume parameter, -v $(pwd)/charts:/charts
	-- inside docker container, 

		root@ran3:~/hw-python/init# docker exec -it eefa /bin/sh
		/ #
		/ # cd charts/
		/charts # ll
		total 12K
		-rw-r--r--    1 root     root         374 Apr 23 15:43 index-cache.yaml
		-rw-r--r--    1 root     root        7.2K Apr 23 15:43 hw-python-1.0.0.tgz
		/charts #


	-- outside, running directory
		root@ran3:~/ric-dep/bin/charts# pwd
		/root/ric-dep/bin/charts
		root@ran3:~/ric-dep/bin/charts# ll
		total 12K
		-rw-r--r-- 1 root root  374 Apr 23 11:43 index-cache.yaml
		-rw-r--r-- 1 root root 7.3K Apr 23 11:43 hw-python-1.0.0.tgz



(4) deploy(install) xapp with helm 

  -- Option.1 : using "dms_cli install" command

	root@ran3:~/hw-python/init# dms_cli install hw-python 1.0.0 ricxapp
	status: OK

  -- Option.2 :  directly install helm chart which was downloaded by dms_cli

	$ [CHART_REPO_URL=http://<ip>:<port>] dms_cli download_helm_chart <chart-name> <version>

	  root@ran3:~/hw-go# dms_cli download_helm_chart hw-go 1.0.0
	  status: OK

	  root@ran3:~/hw-go# ll
	  ...
	  -rw-r--r-- 1 root root 7.5K Apr 23 22:57 hw-go-1.0.0.tgz

	  And then untar this file and if necessary, modify resources and install



	< in k9s >
	NAMESPACE↑    NAME                                    PF READY STATUS            RESTARTS IP           NODE
	...
	ricxapp       ricxapp-hw-python-6965b44676-tx6sp      ●  0/1   ImagePullBackOff         0 10.244.0.21  ran3


	< Error >

	--> successfully deploying but errors with ImagePullBackOff
		That's because of the following event log
		Unable to retrieve some image pull secrets (nexus3-o-ran-sc-org-10004); attempting to pull the image may not succeed.

		in image: nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0

		--> not finding the proper image source from nexus3
			maybe correct path or image, then it will be loaded and worked


		  Events:                                                                                                                                                                                                                                                             
			Type     Reason         Age                From               Message                                                                                                                                                                           
			----     ------         ----               ----               -------                                                                                                                                                                           
			Normal   Scheduled      29s                default-scheduler  Successfully assigned ricxapp/ricxapp-hw-python-6965b44676-v9mzz to ran3                                                                                                          
			Normal   Pulling        17s (x2 over 29s)  kubelet            Pulling image "nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0"                                                                                                        
			Warning  Failed         17s (x2 over 28s)  kubelet            Failed to pull image "nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0": rpc error: code = NotFound desc = failed to pull and unpack image "nexus3.o-ran-sc.org:10004/o-
		  ran-sc/ric-app-hw-python:1.1.0": failed to resolve reference "nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0": nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0: not found                                                                    
			Warning  Failed         17s (x2 over 28s)  kubelet    k       Error: ErrImagePull                                                                                                                                                               
			Warning  FailedToRetrieveImagePullSecret  2s (x4 over 29s)   kubelet            Unable to retrieve some image pull secrets (nexus3-o-ran-sc-org-10004); attempting to pull the image may not succeed.                                                             
			Normal   BackOff        2s (x2 over 28s)   kubelet            Back-off pulling image "nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0"                                                                                               
			Warning  Failed         2s (x2 over 28s)   kubelet            Error: ImagePullBackOff                                                                                                                                                           


	< Solved >
	--> see 3-2's solution 
		



3-2. Software, xApp, Installation and Deployment - hw-go
-----------------------------------------------------------
https://wiki.o-ran-sc.org/download/attachments/51904936/demo_f_release.txt?version=2&modificationDate=1655964027497&api=v2

(1) install 

	******************* HW-GO
	git clone https://gerrit.o-ran-sc.org/r/ric-app/hw-go
	cd hw-go
	docker build -t example.com:80/hw-go:1.2 .
	export CHART_REPO_URL=http://0.0.0.0:8090
	vi config/config-file.json
		modify tag = 1.2
		modify example.com:80 for "registry"
		modify name in image to "hw-go"
	dms_cli onboard ./config/config-file.json ./config/schema.json



(2) deploy
	dms_cli install hw-go 1.0.0 ricxapp


(3) error 
	Error: ErrImagePull



(4) < Solved > use containerd runtime image

		* Reason: 
			- image, 'example.com:80/hw-go' is made of 'docker build'
			- But, after kubernetes v1.24, "containerd" is used as a container runtime
			- So, docker image should be converted into containerd format


		* procedures
			- convert to containerd image
				docker save -o hw-go.tar example.com:80/hw-go:1.2
				
			- import saved tar file 
		   		ctr -n=k8s.io image import hw-go.tar	

				( -n=k8s.io MUST be presented for kubernetes image )

  			- check list, not using 'crictl images', but use 'ctr image'
				ctr -n=k8s.io image list
				...
				docker.io/library/hw-go:latest

			- need to tag(modify name) 
  				ctr -n=k8s.io image tag docker.io/library/hw-go:latest example.com:80/hw-go:1.2
				example.com:80/hw-go:1.2



(5)  install again with helm chart command
	root@ran3:~/ric-dep/bin/charts/hw-go# helm install -n ricxapp hw-go ./
	NAME: hw-go
	LAST DEPLOYED: Wed Apr 24 00:43:04 2024
	NAMESPACE: ricxapp
	STATUS: deployed
	REVISION: 1
	TEST SUITE: None


	< in k9s display >
	ricxapp       ricxapp-hw-go-7c8945ccb6-k2rkn      ●  1/1   Running   0 10.244.0.27  ran3  95m


	< kubectl log >
	root@ran3:~/ric-dep/bin/charts/hw-go# kubectl logs -n ricxapp ricxapp-hw-go-7c8945ccb6-k2rkn
	{"ts":1713933868751,"crit":"INFO","id":"hw-go","mdc":{"time":"2024-04-24T04:44:28"},"msg":"Using config file: config/config-file.json"}
	{"ts":1713933868752,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Serving metrics on: url=/ric/v1/metrics namespace=ricxapp"}
	redis: got 7 elements in COMMAND reply, wanted 6
	{"ts":1713933868758,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp SDL Stored The total number of stored SDL transactions map[]}"}
	{"ts":1713933868758,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp SDL StoreError The total number of SDL store errors map[]}"}
	redis: got 7 elements in COMMAND reply, wanted 6
	{"ts":1713933868763,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp hw_go RICIndicationRx Total number of RIC Indication message received map[]}"}
	1713933868763 7/RMR [INFO] ric message routing library on SI95 p=4560 mv=3 flg=00 id=a (d07cc97 4.7.0 built: Apr  1 2021)
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"new rmrClient with parameters: ProtPort=4560 MaxSize=2072 ThreadType=0 StatDesc=RMR LowLatency=false FastAck=false Policies=[1]"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp RMR Transmitted The total number of transmited RMR messages map[]}"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp RMR Received The total number of received RMR messages map[]}"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp RMR TransmitError The total number of RMR transmission errors map[]}"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Register new counter with opts: {ricxapp RMR ReceiveError The total number of RMR receive errors map[]}"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Interface name is not able to resolve route ip+net: invalid network interface name"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"Xapp started, listening on: :8080"}
	{"ts":1713933868764,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:28"},"msg":"rmrClient: Waiting for RMR to be ready ..."}
	{"ts":1713933869766,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:29"},"msg":"rmrClient: RMR is ready after 1 seconds waiting..."}
	{"ts":1713933869767,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:29"},"msg":"xApp ready call back received"}
	1713933869767 7/RMR [INFO] sends: ts=1713933869 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=localhost:4591 open=0 succ=0 fail=0 (hard=0 soft=0)
	1713933869767 7/RMR [INFO] sends: ts=1713933869 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=localhost:4560 open=0 succ=0 fail=0 (hard=0 soft=0)
	1713933869767 7/RMR [INFO] sends: ts=1713933869 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
	{"ts":1713933869770,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:29"},"msg":"List for connected eNBs :"}
	{"ts":1713933869770,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:29"},"msg":"List of connected gNBs :"}
	RMR is ready now ...
	{"ts":1713933873765,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:33"},"msg":"Application='hw-go' is not ready yet, waiting ..."}
	{"ts":1713933875154,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:35"},"msg":"restapi: method=GET url=/ric/v1/health/alive"}
	{"ts":1713933875154,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:35"},"msg":"restapi: method=GET url=/ric/v1/health/ready"}
	{"ts":1713933878770,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"getService: SERVICE_RICXAPP_HW-GO_HTTP_PORT [tcp: 10.104.238.203:8080]"}
	{"ts":1713933878770,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"getService: SERVICE_RICXAPP_HW-GO_RMR_PORT [tcp: 10.107.149.103:4560]"}
	{"ts":1713933878789,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"restapi: method=GET url=/ric/v1/config"}
	{"ts":1713933878790,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"Inside appconfigHandler"}
	{"ts":1713933878794,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"Post to 'http://service-ricplt-appmgr-http.ricplt:8080/ric/v1/register' done, status:201 Created"}
	{"ts":1713933878794,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"Registration done, proceeding with startup ..."}
	{"ts":1713933878835,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"restapi: method=GET url=/ric/v1/config"}
	{"ts":1713933878835,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:38"},"msg":"Inside appconfigHandler"}
	{"ts":1713933890153,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:50"},"msg":"restapi: method=GET url=/ric/v1/health/ready"}
	{"ts":1713933890154,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:44:50"},"msg":"restapi: method=GET url=/ric/v1/health/alive"}
	1713933900834 7/RMR [INFO] sends: ts=1713933900 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=localhost:4591 open=0 succ=0 fail=0 (hard=0 soft=0)
	1713933900834 7/RMR [INFO] sends: ts=1713933900 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=localhost:4560 open=0 succ=0 fail=0 (hard=0 soft=0)
	1713933900834 7/RMR [INFO] sends: ts=1713933900 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=0 succ=0 fail=0 (hard=0 soft=0)
	1713933900834 7/RMR [INFO] sends: ts=1713933900 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
	1713933900834 7/RMR [INFO] sends: ts=1713933900 src=service-ricxapp-hw-go-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
	{"ts":1713933905155,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:45:05"},"msg":"restapi: method=GET url=/ric/v1/health/ready"}
	{"ts":1713933905156,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:45:05"},"msg":"restapi: method=GET url=/ric/v1/health/alive"}
	{"ts":1713933920154,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:45:20"},"msg":"restapi: method=GET url=/ric/v1/health/ready"}
	{"ts":1713933920155,"crit":"INFO","id":"hw-go","mdc":{"CONTAINER_NAME":"","HOST_NAME":"","HWApp":"0.0.1","PID":"7","POD_NAME":"","SERVICE_NAME":"","SYSTEM_NAME":"","time":"2024-04-24T04:45:20"},"msg":"restapi: method=GET url=/ric/v1/health/alive"}











	



4. Uninstall
-------------
	root@ran3:~/hw-python/init# dms_cli uninstall hw-python ricxapp
	status: OK

	or 
	helm uninstall  command









-----------
 ETC 
-----------

	root@ran3:~/hw-python/init# helm ls -A
	NAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART               APP VERSION
	hw-python               ricxapp         1               2024-04-23 12:06:56.320587726 -0400 EDT deployed        hw-python-1.0.0     1.0
	kong                    kong            1               2024-04-23 11:17:35.831725082 -0400 EDT deployed        ingress-0.12.0      3.6
	r4-a1mediator           ricplt          1               2024-04-23 11:23:43.092638825 -0400 EDT deployed        a1mediator-3.0.0    1.0
	r4-alarmmanager         ricplt          1               2024-04-23 11:24:19.864493459 -0400 EDT deployed        alarmmanager-5.0.0  1.0
	r4-appmgr               ricplt          1               2024-04-23 11:23:05.095988056 -0400 EDT deployed        appmgr-3.0.0        1.0
	r4-dbaas                ricplt          1               2024-04-23 11:22:55.877535939 -0400 EDT deployed        dbaas-2.0.0         1.0
	r4-e2mgr                ricplt          1               2024-04-23 11:23:24.504191626 -0400 EDT deployed        e2mgr-3.0.0         1.0
	r4-e2term               ricplt          1               2024-04-23 11:23:33.661875898 -0400 EDT deployed        e2term-3.0.0        1.0
	r4-infrastructure       ricplt          1               2024-04-23 11:22:42.467162839 -0400 EDT deployed        infrastructure-3.0.01.0
	r4-o1mediator           ricplt          1               2024-04-23 11:24:10.703868189 -0400 EDT deployed        o1mediator-3.0.0    1.0
	r4-rtmgr                ricplt          1               2024-04-23 11:23:15.573521979 -0400 EDT deployed        rtmgr-3.0.0         1.0
	r4-submgr               ricplt          1               2024-04-23 11:23:52.089692238 -0400 EDT deployed        submgr-3.0.0        1.0
	r4-vespamgr             ricplt          1               2024-04-23 11:24:01.333669625 -0400 EDT deployed        vespamgr-3.0.0      1.0

	root@ran3:~/hw-python/init# helm repo list
	NAME    URL
	kong    https://charts.konghq.com
	local   http://127.0.0.1:8879/charts




	root@ran3:~/hw-python/init# helm get manifest -n ricxapp hw-python
	---
	# Source: hw-python/templates/appconfig.yaml
	apiVersion: v1
	kind: ConfigMap
	metadata:
	  name: configmap-ricxapp-hw-python-appconfig
	...
	# Source: hw-python/templates/appenv.yaml 
	...
	# Source: hw-python/templates/service-rmr.yaml
	...
	 # Source: hw-python/templates/service-http.yaml
	  apiVersion: v1
	  kind: Service
	  metadata:
		name: service-ricxapp-hw-python-http
		namespace: ricxapp
		labels:
		  app: ricxapp-hw-python
		  chart: hw-python-1.0.0
		  release: hw-python
		  heritage: Helm
	  spec:
		type: ClusterIP
		ports:
		  - port: 8080
			targetPort: http
			protocol: TCP
			name: http
		selector:
		  app: ricxapp-hw-python
		  release: hw-python

	  # Source: hw-python/templates/deployment.yaml
	  apiVersion: apps/v1
	  kind: Deployment
	  metadata:
		name: ricxapp-hw-python
		labels:
		  app: ricxapp-hw-python
		  chart: hw-python-1.0.0
		  release: hw-python
		  heritage: Helm
	  spec:
		replicas: 1
		selector:
		  matchLabels:
			app: ricxapp-hw-python
			release: hw-python
		template:
		  metadata:
			labels:
			  app: ricxapp-hw-python
			  kubernetes_name: ricxapp_hw-python
			  release: hw-python
		  spec:
			hostname: hw-python
			imagePullSecrets:
			  - name: nexus3-o-ran-sc-org-10004
			volumes:
			  - name: config-volume
				configMap:
				  name: configmap-ricxapp-hw-python-appconfig
			containers:
			  - name: hw-python
				image: "nexus3.o-ran-sc.org:10004/o-ran-sc/ric-app-hw-python:1.1.0"
				imagePullPolicy: IfNotPresent
				ports:
				  - name: http
					containerPort: 8080
					protocol: TCP
				  - name: rmrroute
					containerPort: 4561
					protocol: TCP
				  - name: rmrdata
					containerPort: 4560
					protocol: TCP
				volumeMounts:
				  - name: config-volume
					mountPath: /opt/ric/config
				envFrom:
				  - configMapRef:
					  name: configmap-ricxapp-hw-python-appenv
				  - configMapRef:
					  name: dbaas-appconfig































